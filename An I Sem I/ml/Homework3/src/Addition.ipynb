{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Addition.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"0XbPmnyc0wvE","colab_type":"text"},"cell_type":"markdown","source":["# **Uploads**\n","\n","---\n","\n","Upload necessary files"]},{"metadata":{"id":"GNBG3R5G8c6e","colab_type":"code","outputId":"b6ce306d-dfa7-411d-b41f-edd9de548c19","executionInfo":{"status":"ok","timestamp":1547581164914,"user_tz":-120,"elapsed":21310,"user":{"displayName":"Ionut Calofir","photoUrl":"https://lh4.googleusercontent.com/-FegDwQfAEhI/AAAAAAAAAAI/AAAAAAAAB4U/HLBTQ0VCm98/s64/photo.jpg","userId":"09436986145457248242"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":"OK"}},"base_uri":"https://localhost:8080/","height":118}},"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-631e1472-8a36-44b7-a03f-86c1e31d05b2\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-631e1472-8a36-44b7-a03f-86c1e31d05b2\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving data_generator.py to data_generator (1).py\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'data_generator.py': b'import random\\nimport cv2\\nimport numpy as np\\n\\nfrom imgaug import augmenters as iaa\\nfrom tensorflow.keras import datasets\\n\\n(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\\n\\ndef sometimes(aug): return iaa.Sometimes(0.5, aug)\\n\\nseq = iaa.Sequential([\\n    iaa.Affine(\\n        scale={\"x\": (0.8, 1), \"y\": (0.8, 1)},\\n        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\\n        rotate=(-15, 15),\\n        shear=(-5, 5),\\n        cval=(0, 0),\\n        mode=\\'constant\\'\\n    )\\n])\\n\\n\\ndef crop_number(number):\\n    \"\"\"\\n        Crops a MNIST digit to its containing bounding box with some random noise.\\n    \"\"\"\\n    vsum = np.sum(number, axis=0)\\n    vsum[vsum > 0] = 1\\n    vdif = np.diff(vsum)\\n    vdif[vdif > 0] = 1\\n    xs = np.argwhere(vdif > 0).ravel()\\n\\n    random_cut1 = np.random.randint(-1, 3)\\n    random_cut2 = np.random.randint(-1, 3)\\n\\n    try:\\n        cropped_number = number[0:28, xs[0] - random_cut1:xs[1] + random_cut2]\\n        if cropped_number.shape[1] < 6:\\n            raise Exception\\n    except:\\n        cropped_number = number\\n\\n    return cropped_number\\n\\n\\ndef pad_image(number, target_shape=(28, 84)):\\n    \"\"\"\\n        Makes all images the same shape\\n    \"\"\"\\n    _shape = number.shape\\n\\n    height_pad = (-_shape[0] + target_shape[0]) // 2\\n    width_pad = (-_shape[1] + target_shape[1]) // 2\\n\\n    padded = cv2.copyMakeBorder(number,\\n                                height_pad,\\n                                height_pad,\\n                                width_pad + int(_shape[1] % 2 == 1),\\n                                width_pad,\\n                                cv2.BORDER_CONSTANT,\\n                                value=0)\\n    return padded\\n\\n\\ndef generate_images(data_x, data_y, batch_size, length=255):\\n    \"\"\"\\n        Generates images containing numbers from MNIST with random translations.\\n    \"\"\"\\n\\n    while True:\\n\\n        x_batch = []\\n        y_numbers_batch = []\\n        y_results = []\\n\\n        for _ in range(batch_size):\\n            x = [np.zeros((28, 0)), np.zeros((28, 0))]\\n            y_numbers = []\\n\\n            for num in range(2):\\n                random_num = random.randrange(length)\\n                decimal = str(random_num)\\n\\n                y_numbers.append(np.array([random_num]))\\n\\n                for digit in decimal:\\n                    numbers = np.argwhere(data_y == int(digit))\\n\\n                    loc = np.random.choice(numbers.ravel(), 1)\\n                    number = np.squeeze(data_x[loc])\\n                    augmented_number = seq.augment_images([number])[0]\\n                    cropped_number = crop_number(augmented_number)\\n\\n                    x[num] = np.hstack((x[num], cropped_number))\\n                x[num] = pad_image(x[num])\\n\\n            x_batch.append(x)\\n            y_numbers_batch.append(y_numbers)\\n            y_results.append(y_numbers[-1] + y_numbers[-2])\\n\\n        yield np.array(x_batch), np.squeeze(np.array(y_numbers_batch)), np.array(y_results)\\n\\n\\ndef training_generator(batch_size=32):\\n    \"\"\"\\n        Use this function to generate training samples. Images are generated using the training set of MNIST.\\n        Example usage:\\n\\n        generator = training_generator(batch_size=8) # batch size of 8\\n\\n        x, numbers, numbers_sum = next(generator)\\n\\n        # x.shape == (8, 2, 28, 84)     # 8 pairs of images with height 28px and width 84px\\n        # numbers.shape == (8, 2)       # 8 pairs of numbers corresponding to the images\\n        # numbers_sum.shape == (8, 1)   # 8 numbers that represent the sum of the numbers from the images\\n\\n    \"\"\"\\n    return generate_images(x_train, y_train, batch_size)\\n\\n\\ndef test_generator(batch_size=32):\\n    \"\"\"\\n        Use this function to generate test samples. Images are generated using the test set of MNIST.\\n        Example usage:\\n\\n        generator = test_generator(batch_size=8) # batch size of 8\\n\\n        x, numbers, numbers_sum = next(generator)\\n\\n        # x.shape == (8, 2, 28, 84)     # 8 pairs of images with height 28px and width 84px\\n        # numbers.shape == (8, 2)       # 8 pairs of numbers corresponding to the images\\n        # numbers_sum.shape == (8, 1)   # 8 numbers that represent the sum of the numbers from the images\\n\\n    \"\"\"\\n    return generate_images(x_test, y_test, batch_size)\\n'}"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"k_A39PDe87m9","colab_type":"text"},"cell_type":"markdown","source":["# **Imports**\n","\n","---\n","\n","Import necessary libraries and set constant variables"]},{"metadata":{"id":"h7KYqIaR89P6","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline\n","import cv2\n","import tensorflow as tf\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import accuracy_score\n","\n","from data_generator import training_generator, test_generator\n","\n","NUM_CLASSES = 254 + 254 + 1 # number of classes\n","X_ROWS = 7\n","Y_ROWS = 3\n","CHARS_X = ' +0123456789' # characters present in the input\n","CHARS_Y = ' 0123456789' # characters present in the output"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QO-WBbFU8_Lr","colab_type":"text"},"cell_type":"markdown","source":["# **Utils**\n","\n","---\n","\n","Utils functions"]},{"metadata":{"id":"YTqYI9Gx9Ci0","colab_type":"code","colab":{}},"cell_type":"code","source":["def generate_balanced_data(no_ex_per_class=100, data_type='train'):\n","  classes = NUM_CLASSES * [0]\n","  per = 0\n","  X = []\n","  y = []\n","  \n","  if data_type == 'train':\n","    generator = training_generator(batch_size=1)\n","  elif data_type == 'test':\n","    generator = test_generator(batch_size=1)\n","  else:\n","    raise Exception('Invalid data type!')\n","  \n","  while True:\n","    x, numbers, numbers_sum = next(generator)\n","    nr = '{0}+{1}'.format(numbers[0], numbers[1])\n","    s = str(numbers_sum[0][0])\n","    \n","    if classes[int(s)] < no_ex_per_class:\n","      classes[int(s)] += 1\n","      X.append(nr)\n","      y.append(s)\n","      \n","      if int((sum(classes) * 100) / (NUM_CLASSES * no_ex_per_class)) > per:\n","        per = int((sum(classes) * 100) / (NUM_CLASSES * no_ex_per_class))\n","        print('--{0}%/100%--'.format(per))\n","\n","#     if (sum(classes) == NUM_CLASSES * no_ex_per_class):\n","#       break\n","    if int((sum(classes) * 100) / (NUM_CLASSES * no_ex_per_class)) >= 90: # because otherwise it takes too long\n","      break\n","    \n","  X = np.array(X)\n","  y = np.array(y)\n","\n","  return X, y\n","\n","def encode_x_str(s):\n","  s = ' ' * (X_ROWS - len(s)) + s\n","  x = np.zeros((X_ROWS, len(CHARS_X)))\n","  \n","  for i in range(X_ROWS):\n","    x[i, CHARS_X.find(s[i])] = 1\n","    \n","  return x\n","\n","def encode_y_str(s):\n","  s = ' ' * (Y_ROWS - len(s)) + s\n","  y = np.zeros((Y_ROWS, len(CHARS_Y)))\n","  \n","  for i in range(Y_ROWS):\n","    y[i, CHARS_Y.find(s[i])] = 1\n","    \n","  return y\n","\n","def decode_x_str(x):\n","  s = ''\n","  for i in range(X_ROWS):\n","    pos = np.argmax(x[i])\n","    if pos == 0:\n","      continue\n","      \n","    s += CHARS_X[pos]\n","    \n","  return s\n","\n","def decode_y_str(y):\n","  s = ''\n","  for i in range(Y_ROWS):\n","    pos = np.argmax(y[i])\n","    if pos == 0:\n","      continue\n","      \n","    s += CHARS_Y[pos]\n","    \n","  return s\n","\n","def encode_x(X):\n","  X_new = []\n","  for i in range(X.shape[0]):\n","    X_new.append(encode_x_str(X[i]))\n","    \n","  return np.array(X_new)\n","\n","def encode_y(y):\n","  y_new = []\n","  for i in range(y.shape[0]):\n","    y_new.append(encode_y_str(y[i]))\n","  y_new = np.array(y_new)\n","    \n","  y_time_step = []\n","  y_time_step.append(y_new[:, 0, :])\n","  y_time_step.append(y_new[:, 1, :])\n","  y_time_step.append(y_new[:, 2, :])\n","    \n","  return y_new, np.array(y_time_step)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jsPaAoSoO5xn","colab_type":"text"},"cell_type":"markdown","source":["Generating the data"]},{"metadata":{"id":"i4XriDSh9nA0","colab_type":"code","outputId":"ce4577f9-afe0-46b5-fc27-b0f34bc6cb10","executionInfo":{"status":"ok","timestamp":1547585208974,"user_tz":-120,"elapsed":651737,"user":{"displayName":"Ionut Calofir","photoUrl":"https://lh4.googleusercontent.com/-FegDwQfAEhI/AAAAAAAAAAI/AAAAAAAAB4U/HLBTQ0VCm98/s64/photo.jpg","userId":"09436986145457248242"}},"colab":{"base_uri":"https://localhost:8080/","height":4706}},"cell_type":"code","source":["X_train, y_train = generate_balanced_data(no_ex_per_class=100, data_type='train')\n","X_val, y_val = generate_balanced_data(no_ex_per_class=10, data_type='test')\n","X_test, y_test = generate_balanced_data(no_ex_per_class=10, data_type='test')\n","\n","X_train_encoded = encode_x(X_train)\n","y_train_encoded, y_train_encoded_time_step = encode_y(y_train)\n","X_val_encoded = encode_x(X_val)\n","y_val_encoded, y_val_encoded_time_step = encode_y(y_val)\n","X_test_encoded = encode_x(X_test)\n","y_test_encoded, y_test_encoded_time_step = encode_y(y_test)"],"execution_count":51,"outputs":[{"output_type":"stream","text":["--1%/100%--\n","--2%/100%--\n","--3%/100%--\n","--4%/100%--\n","--5%/100%--\n","--6%/100%--\n","--7%/100%--\n","--8%/100%--\n","--9%/100%--\n","--10%/100%--\n","--11%/100%--\n","--12%/100%--\n","--13%/100%--\n","--14%/100%--\n","--15%/100%--\n","--16%/100%--\n","--17%/100%--\n","--18%/100%--\n","--19%/100%--\n","--20%/100%--\n","--21%/100%--\n","--22%/100%--\n","--23%/100%--\n","--24%/100%--\n","--25%/100%--\n","--26%/100%--\n","--27%/100%--\n","--28%/100%--\n","--29%/100%--\n","--30%/100%--\n","--31%/100%--\n","--32%/100%--\n","--33%/100%--\n","--34%/100%--\n","--35%/100%--\n","--36%/100%--\n","--37%/100%--\n","--38%/100%--\n","--39%/100%--\n","--40%/100%--\n","--41%/100%--\n","--42%/100%--\n","--43%/100%--\n","--44%/100%--\n","--45%/100%--\n","--46%/100%--\n","--47%/100%--\n","--48%/100%--\n","--49%/100%--\n","--50%/100%--\n","--51%/100%--\n","--52%/100%--\n","--53%/100%--\n","--54%/100%--\n","--55%/100%--\n","--56%/100%--\n","--57%/100%--\n","--58%/100%--\n","--59%/100%--\n","--60%/100%--\n","--61%/100%--\n","--62%/100%--\n","--63%/100%--\n","--64%/100%--\n","--65%/100%--\n","--66%/100%--\n","--67%/100%--\n","--68%/100%--\n","--69%/100%--\n","--70%/100%--\n","--71%/100%--\n","--72%/100%--\n","--73%/100%--\n","--74%/100%--\n","--75%/100%--\n","--76%/100%--\n","--77%/100%--\n","--78%/100%--\n","--79%/100%--\n","--80%/100%--\n","--81%/100%--\n","--82%/100%--\n","--83%/100%--\n","--84%/100%--\n","--85%/100%--\n","--86%/100%--\n","--87%/100%--\n","--88%/100%--\n","--89%/100%--\n","--90%/100%--\n","--1%/100%--\n","--2%/100%--\n","--3%/100%--\n","--4%/100%--\n","--5%/100%--\n","--6%/100%--\n","--7%/100%--\n","--8%/100%--\n","--9%/100%--\n","--10%/100%--\n","--11%/100%--\n","--12%/100%--\n","--13%/100%--\n","--14%/100%--\n","--15%/100%--\n","--16%/100%--\n","--17%/100%--\n","--18%/100%--\n","--19%/100%--\n","--20%/100%--\n","--21%/100%--\n","--22%/100%--\n","--23%/100%--\n","--24%/100%--\n","--25%/100%--\n","--26%/100%--\n","--27%/100%--\n","--28%/100%--\n","--29%/100%--\n","--30%/100%--\n","--31%/100%--\n","--32%/100%--\n","--33%/100%--\n","--34%/100%--\n","--35%/100%--\n","--36%/100%--\n","--37%/100%--\n","--38%/100%--\n","--39%/100%--\n","--40%/100%--\n","--41%/100%--\n","--42%/100%--\n","--43%/100%--\n","--44%/100%--\n","--45%/100%--\n","--46%/100%--\n","--47%/100%--\n","--48%/100%--\n","--49%/100%--\n","--50%/100%--\n","--51%/100%--\n","--52%/100%--\n","--53%/100%--\n","--54%/100%--\n","--55%/100%--\n","--56%/100%--\n","--57%/100%--\n","--58%/100%--\n","--59%/100%--\n","--60%/100%--\n","--61%/100%--\n","--62%/100%--\n","--63%/100%--\n","--64%/100%--\n","--65%/100%--\n","--66%/100%--\n","--67%/100%--\n","--68%/100%--\n","--69%/100%--\n","--70%/100%--\n","--71%/100%--\n","--72%/100%--\n","--73%/100%--\n","--74%/100%--\n","--75%/100%--\n","--76%/100%--\n","--77%/100%--\n","--78%/100%--\n","--79%/100%--\n","--80%/100%--\n","--81%/100%--\n","--82%/100%--\n","--83%/100%--\n","--84%/100%--\n","--85%/100%--\n","--86%/100%--\n","--87%/100%--\n","--88%/100%--\n","--89%/100%--\n","--90%/100%--\n","--1%/100%--\n","--2%/100%--\n","--3%/100%--\n","--4%/100%--\n","--5%/100%--\n","--6%/100%--\n","--7%/100%--\n","--8%/100%--\n","--9%/100%--\n","--10%/100%--\n","--11%/100%--\n","--12%/100%--\n","--13%/100%--\n","--14%/100%--\n","--15%/100%--\n","--16%/100%--\n","--17%/100%--\n","--18%/100%--\n","--19%/100%--\n","--20%/100%--\n","--21%/100%--\n","--22%/100%--\n","--23%/100%--\n","--24%/100%--\n","--25%/100%--\n","--26%/100%--\n","--27%/100%--\n","--28%/100%--\n","--29%/100%--\n","--30%/100%--\n","--31%/100%--\n","--32%/100%--\n","--33%/100%--\n","--34%/100%--\n","--35%/100%--\n","--36%/100%--\n","--37%/100%--\n","--38%/100%--\n","--39%/100%--\n","--40%/100%--\n","--41%/100%--\n","--42%/100%--\n","--43%/100%--\n","--44%/100%--\n","--45%/100%--\n","--46%/100%--\n","--47%/100%--\n","--48%/100%--\n","--49%/100%--\n","--50%/100%--\n","--51%/100%--\n","--52%/100%--\n","--53%/100%--\n","--54%/100%--\n","--55%/100%--\n","--56%/100%--\n","--57%/100%--\n","--58%/100%--\n","--59%/100%--\n","--60%/100%--\n","--61%/100%--\n","--62%/100%--\n","--63%/100%--\n","--64%/100%--\n","--65%/100%--\n","--66%/100%--\n","--67%/100%--\n","--68%/100%--\n","--69%/100%--\n","--70%/100%--\n","--71%/100%--\n","--72%/100%--\n","--73%/100%--\n","--74%/100%--\n","--75%/100%--\n","--76%/100%--\n","--77%/100%--\n","--78%/100%--\n","--79%/100%--\n","--80%/100%--\n","--81%/100%--\n","--82%/100%--\n","--83%/100%--\n","--84%/100%--\n","--85%/100%--\n","--86%/100%--\n","--87%/100%--\n","--88%/100%--\n","--89%/100%--\n","--90%/100%--\n"],"name":"stdout"}]},{"metadata":{"id":"SSOvdyC2KToG","colab_type":"text"},"cell_type":"markdown","source":["Search the best value for the hidden units."]},{"metadata":{"id":"QqbJ0H2q4YLT","colab_type":"code","outputId":"ec05fd78-0cc1-4931-9f13-e45c8217410e","executionInfo":{"status":"ok","timestamp":1547587823042,"user_tz":-120,"elapsed":3254617,"user":{"displayName":"Ionut Calofir","photoUrl":"https://lh4.googleusercontent.com/-FegDwQfAEhI/AAAAAAAAAAI/AAAAAAAAB4U/HLBTQ0VCm98/s64/photo.jpg","userId":"09436986145457248242"}},"colab":{"base_uri":"https://localhost:8080/","height":1458}},"cell_type":"code","source":["n_a_v = [64, 128]\n","models = []\n","\n","for n_a in n_a_v:\n","  # training\n","  # ----------------------------------------------------------------------------\n","  LSTM_cell_encoder = tf.keras.layers.LSTM(n_a, return_state=True)\n","  LSTM_cell_decoder = tf.keras.layers.LSTM(n_a, return_state=True)\n","  densor = tf.keras.layers.Dense(len(CHARS_Y), activation=tf.nn.softmax)\n","  reshapor_x = tf.keras.layers.Reshape((1, 12))\n","  reshapor_y = tf.keras.layers.Reshape((1, 11))\n","\n","  # encoder\n","  X = tf.keras.layers.Input(shape=(X_ROWS, len(CHARS_X)))\n","  a0 = tf.keras.layers.Input(shape=(n_a,))\n","  c0 = tf.keras.layers.Input(shape=(n_a,))\n","\n","  a = a0\n","  c = c0\n","\n","  for t in range(X_ROWS):\n","    x = tf.keras.layers.Lambda(lambda x: x[:, t, :])(X)\n","    x = reshapor_x(x) # tensor needs to be of shape (batch, time step, state)\n","    a, _, c = LSTM_cell_encoder(x, initial_state=[a, c])\n","\n","  # decoder\n","  y_init = tf.keras.layers.Input(shape=(1, len(CHARS_Y)))\n","  Y = tf.keras.layers.Input(shape=(Y_ROWS, len(CHARS_Y)))\n","\n","  outputs = []\n","\n","  for t in range(Y_ROWS):\n","    if t == 0:\n","      y = tf.keras.layers.Lambda(lambda y: y[:, 0, :])(y_init) # after this reshape?\n","    else:\n","      y = tf.keras.layers.Lambda(lambda y: y[:, t - 1, :])(Y)\n","    y = reshapor_y(y)\n","    \n","    a, _, c = LSTM_cell_decoder(y, initial_state=[a, c])\n","  \n","    out = densor(a)  \n","    outputs.append(out)\n","    \n","  model = tf.keras.Model(inputs=[X, a0, c0, y_init, Y], outputs=outputs)\n","\n","  opt = tf.keras.optimizers.Adam()\n","  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","  m = X_train_encoded.shape[0]\n","  a0 = np.zeros((m, n_a))\n","  c0 = np.zeros((m, n_a))\n","  y_init = np.zeros((m, 1, len(CHARS_Y)))\n","\n","  model.fit([X_train_encoded, a0, c0, y_init, y_train_encoded], list(y_train_encoded_time_step), epochs=20)\n","  \n","  # predicting\n","  # ----------------------------------------------------------------------------\n","  #encoder\n","  X_ = tf.keras.layers.Input(shape=(X_ROWS, len(CHARS_X)))\n","  a0_ = tf.keras.layers.Input(shape=(n_a,))\n","  c0_ = tf.keras.layers.Input(shape=(n_a,))\n","\n","  a_ = a0_\n","  c_ = c0_\n","\n","  for t in range(X_ROWS):\n","    x_ = tf.keras.layers.Lambda(lambda x: x[:, t, :])(X_)\n","    x_ = reshapor_x(x_) # tensor needs to be of shape (batch, time step, state)\n","    a_, _, c_ = LSTM_cell_encoder(x_, initial_state=[a_, c_])\n","\n","  # decoder \n","  xx_ = tf.keras.layers.Input(shape=(1, len(CHARS_Y)))\n","  inp = xx_\n","\n","  outputs_ = []\n","\n","  for t in range(Y_ROWS):\n","    y_ = tf.keras.layers.Lambda(lambda y: y[:, 0, :])(inp)\n","  \n","    y_ = reshapor_y(y_)\n","    \n","    a_, _, c_ = LSTM_cell_decoder(y_, initial_state=[a_, c_])\n","  \n","    out_ = densor(a_) \n","  \n","    inp = reshapor_y(out_)\n","    outputs_.append(inp)\n","  \n","  model_inf_ = tf.keras.Model(inputs=[X_, a0_, c0_, xx_], outputs=outputs_)\n","  \n","  m_pos = 1\n","  a0 = np.zeros((m_pos, n_a))\n","  c0 = np.zeros((m_pos, n_a))\n","  xx = np.zeros((m_pos, 1, len(CHARS_Y)))\n","\n","  y_pred = []\n","  for pos in range(X_val_encoded.shape[0]):\n","    p = model_inf_.predict([X_val_encoded[pos:pos+m_pos, :, :], a0, c0, xx])\n","    y_pred.append(decode_y_str(p))\n","    \n","  acc = accuracy_score(y_val, y_pred)\n","  models.append((n_a, acc))\n","  \n","models.sort(key=lambda k: k[1], reverse=True)\n","print('Best model hyperparameters:\\n \\\n","Accuracy: {0}\\n \\\n","Hidden units: {1}'.format(models[0][1], models[0][0]))"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","45810/45810 [==============================] - 86s 2ms/step - loss: 5.1854 - dense_15_loss: 2.3168 - dense_15_acc: 0.7152 - dense_15_acc_1: 0.1563 - dense_15_acc_2: 0.1016\n","Epoch 2/20\n","45810/45810 [==============================] - 55s 1ms/step - loss: 4.1706 - dense_15_loss: 2.2979 - dense_15_acc: 0.9062 - dense_15_acc_1: 0.3555 - dense_15_acc_2: 0.1129\n","Epoch 3/20\n","45810/45810 [==============================] - 56s 1ms/step - loss: 3.4582 - dense_15_loss: 2.2502 - dense_15_acc: 0.9531 - dense_15_acc_1: 0.5848 - dense_15_acc_2: 0.1377\n","Epoch 4/20\n","45810/45810 [==============================] - 55s 1ms/step - loss: 3.0344 - dense_15_loss: 2.1566 - dense_15_acc: 0.9704 - dense_15_acc_1: 0.7106 - dense_15_acc_2: 0.1706\n","Epoch 5/20\n","45810/45810 [==============================] - 55s 1ms/step - loss: 2.7526 - dense_15_loss: 2.0543 - dense_15_acc: 0.9762 - dense_15_acc_1: 0.7735 - dense_15_acc_2: 0.1984\n","Epoch 6/20\n","45810/45810 [==============================] - 55s 1ms/step - loss: 2.5621 - dense_15_loss: 1.9647 - dense_15_acc: 0.9794 - dense_15_acc_1: 0.8040 - dense_15_acc_2: 0.2257\n","Epoch 7/20\n","45810/45810 [==============================] - 55s 1ms/step - loss: 2.4143 - dense_15_loss: 1.8890 - dense_15_acc: 0.9813 - dense_15_acc_1: 0.8297 - dense_15_acc_2: 0.2490\n","Epoch 8/20\n","45810/45810 [==============================] - 55s 1ms/step - loss: 2.2884 - dense_15_loss: 1.8186 - dense_15_acc: 0.9835 - dense_15_acc_1: 0.8449 - dense_15_acc_2: 0.2688\n","Epoch 9/20\n","45810/45810 [==============================] - 54s 1ms/step - loss: 2.2237 - dense_15_loss: 1.7872 - dense_15_acc: 0.9840 - dense_15_acc_1: 0.8499 - dense_15_acc_2: 0.2697\n","Epoch 10/20\n","45810/45810 [==============================] - 55s 1ms/step - loss: 2.1547 - dense_15_loss: 1.7455 - dense_15_acc: 0.9849 - dense_15_acc_1: 0.8611 - dense_15_acc_2: 0.2848\n","Epoch 11/20\n","45810/45810 [==============================] - 55s 1ms/step - loss: 2.0375 - dense_15_loss: 1.6696 - dense_15_acc: 0.9864 - dense_15_acc_1: 0.8795 - dense_15_acc_2: 0.3112\n","Epoch 12/20\n","45810/45810 [==============================] - 54s 1ms/step - loss: 1.9949 - dense_15_loss: 1.6451 - dense_15_acc: 0.9869 - dense_15_acc_1: 0.8809 - dense_15_acc_2: 0.3146\n","Epoch 13/20\n","45810/45810 [==============================] - 54s 1ms/step - loss: 1.9763 - dense_15_loss: 1.6355 - dense_15_acc: 0.9869 - dense_15_acc_1: 0.8831 - dense_15_acc_2: 0.3166\n","Epoch 14/20\n","45810/45810 [==============================] - 55s 1ms/step - loss: 1.9353 - dense_15_loss: 1.6093 - dense_15_acc: 0.9876 - dense_15_acc_1: 0.8851 - dense_15_acc_2: 0.3227\n","Epoch 15/20\n","45810/45810 [==============================] - 54s 1ms/step - loss: 1.9308 - dense_15_loss: 1.6063 - dense_15_acc: 0.9880 - dense_15_acc_1: 0.8874 - dense_15_acc_2: 0.3355\n","Epoch 16/20\n","45810/45810 [==============================] - 57s 1ms/step - loss: 1.8360 - dense_15_loss: 1.5406 - dense_15_acc: 0.9888 - dense_15_acc_1: 0.8980 - dense_15_acc_2: 0.3514\n","Epoch 17/20\n","45810/45810 [==============================] - 79s 2ms/step - loss: 1.7941 - dense_15_loss: 1.5106 - dense_15_acc: 0.9900 - dense_15_acc_1: 0.9012 - dense_15_acc_2: 0.3596\n","Epoch 18/20\n","45810/45810 [==============================] - 95s 2ms/step - loss: 1.8077 - dense_15_loss: 1.5209 - dense_15_acc: 0.9892 - dense_15_acc_1: 0.8976 - dense_15_acc_2: 0.3546\n","Epoch 19/20\n","45810/45810 [==============================] - 94s 2ms/step - loss: 1.8072 - dense_15_loss: 1.5233 - dense_15_acc: 0.9898 - dense_15_acc_1: 0.8978 - dense_15_acc_2: 0.3594\n","Epoch 20/20\n","45810/45810 [==============================] - 92s 2ms/step - loss: 1.7026 - dense_15_loss: 1.4446 - dense_15_acc: 0.9903 - dense_15_acc_1: 0.9109 - dense_15_acc_2: 0.3874\n","Epoch 1/20\n","45810/45810 [==============================] - 87s 2ms/step - loss: 4.9957 - dense_16_loss: 2.3171 - dense_16_acc: 0.7580 - dense_16_acc_1: 0.1831 - dense_16_acc_2: 0.1003\n","Epoch 2/20\n","45810/45810 [==============================] - 54s 1ms/step - loss: 3.6863 - dense_16_loss: 2.2826 - dense_16_acc: 0.9454 - dense_16_acc_1: 0.4840 - dense_16_acc_2: 0.1205\n","Epoch 3/20\n","45810/45810 [==============================] - 54s 1ms/step - loss: 3.0021 - dense_16_loss: 2.1833 - dense_16_acc: 0.9715 - dense_16_acc_1: 0.7074 - dense_16_acc_2: 0.1606\n","Epoch 4/20\n","45810/45810 [==============================] - 56s 1ms/step - loss: 2.6505 - dense_16_loss: 2.0404 - dense_16_acc: 0.9792 - dense_16_acc_1: 0.7877 - dense_16_acc_2: 0.2006\n","Epoch 5/20\n","45810/45810 [==============================] - 56s 1ms/step - loss: 2.4272 - dense_16_loss: 1.9292 - dense_16_acc: 0.9816 - dense_16_acc_1: 0.8233 - dense_16_acc_2: 0.2306\n","Epoch 6/20\n","45810/45810 [==============================] - 55s 1ms/step - loss: 2.2568 - dense_16_loss: 1.8253 - dense_16_acc: 0.9828 - dense_16_acc_1: 0.8468 - dense_16_acc_2: 0.2585\n","Epoch 7/20\n","45810/45810 [==============================] - 54s 1ms/step - loss: 2.1635 - dense_16_loss: 1.7647 - dense_16_acc: 0.9844 - dense_16_acc_1: 0.8558 - dense_16_acc_2: 0.2774\n","Epoch 8/20\n","45810/45810 [==============================] - 56s 1ms/step - loss: 2.0570 - dense_16_loss: 1.6925 - dense_16_acc: 0.9859 - dense_16_acc_1: 0.8688 - dense_16_acc_2: 0.3011\n","Epoch 9/20\n","45810/45810 [==============================] - 55s 1ms/step - loss: 1.9530 - dense_16_loss: 1.6192 - dense_16_acc: 0.9864 - dense_16_acc_1: 0.8776 - dense_16_acc_2: 0.3269\n","Epoch 10/20\n","45810/45810 [==============================] - 56s 1ms/step - loss: 1.8327 - dense_16_loss: 1.5225 - dense_16_acc: 0.9881 - dense_16_acc_1: 0.8881 - dense_16_acc_2: 0.3647\n","Epoch 11/20\n","45810/45810 [==============================] - 56s 1ms/step - loss: 1.6368 - dense_16_loss: 1.3291 - dense_16_acc: 0.9886 - dense_16_acc_1: 0.8858 - dense_16_acc_2: 0.4500\n","Epoch 12/20\n","45810/45810 [==============================] - 56s 1ms/step - loss: 1.3457 - dense_16_loss: 1.0255 - dense_16_acc: 0.9877 - dense_16_acc_1: 0.8792 - dense_16_acc_2: 0.5931\n","Epoch 13/20\n","45810/45810 [==============================] - 56s 1ms/step - loss: 0.9774 - dense_16_loss: 0.6845 - dense_16_acc: 0.9885 - dense_16_acc_1: 0.8917 - dense_16_acc_2: 0.7641\n","Epoch 14/20\n","45810/45810 [==============================] - 56s 1ms/step - loss: 0.7536 - dense_16_loss: 0.4666 - dense_16_acc: 0.9877 - dense_16_acc_1: 0.8972 - dense_16_acc_2: 0.8536\n","Epoch 15/20\n","45810/45810 [==============================] - 56s 1ms/step - loss: 0.5497 - dense_16_loss: 0.2979 - dense_16_acc: 0.9888 - dense_16_acc_1: 0.9140 - dense_16_acc_2: 0.9208\n","Epoch 16/20\n","45810/45810 [==============================] - 57s 1ms/step - loss: 0.3997 - dense_16_loss: 0.1891 - dense_16_acc: 0.9900 - dense_16_acc_1: 0.9341 - dense_16_acc_2: 0.9554\n","Epoch 17/20\n","45810/45810 [==============================] - 60s 1ms/step - loss: 0.2890 - dense_16_loss: 0.1260 - dense_16_acc: 0.9916 - dense_16_acc_1: 0.9552 - dense_16_acc_2: 0.9719\n","Epoch 18/20\n","45810/45810 [==============================] - 60s 1ms/step - loss: 0.2208 - dense_16_loss: 0.0833 - dense_16_acc: 0.9917 - dense_16_acc_1: 0.9639 - dense_16_acc_2: 0.9833\n","Epoch 19/20\n","45810/45810 [==============================] - 60s 1ms/step - loss: 0.2080 - dense_16_loss: 0.0854 - dense_16_acc: 0.9921 - dense_16_acc_1: 0.9683 - dense_16_acc_2: 0.9770\n","Epoch 20/20\n","45810/45810 [==============================] - 58s 1ms/step - loss: 0.1336 - dense_16_loss: 0.0460 - dense_16_acc: 0.9942 - dense_16_acc_1: 0.9799 - dense_16_acc_2: 0.9908\n","Best model hyperparameters:\n"," Accuracy: 0.9753328967474351\n"," Hidden units: 128\n"],"name":"stdout"}]},{"metadata":{"id":"hFB34NnXKbOX","colab_type":"text"},"cell_type":"markdown","source":["I used two LSTMs. The first LSTM is the encoder and it is used to learn a good representation of the input, its input is the actual input. The second LSTM is the decoder and outputs the sum of the two numbers from the input, its input is the input from the encoder. "]},{"metadata":{"id":"tT96qVjwLKlN","colab_type":"text"},"cell_type":"markdown","source":["Training"]},{"metadata":{"id":"QwlQhlFO_Ut5","colab_type":"code","colab":{}},"cell_type":"code","source":["N_A = 128 # hidden units for the best model\n","LSTM_cell_encoder = tf.keras.layers.LSTM(N_A, return_state=True)\n","LSTM_cell_decoder = tf.keras.layers.LSTM(N_A, return_state=True)\n","densor = tf.keras.layers.Dense(len(CHARS_Y), activation=tf.nn.softmax)\n","reshapor_x = tf.keras.layers.Reshape((1, 12))\n","reshapor_y = tf.keras.layers.Reshape((1, 11))\n","\n","#encoder\n","X = tf.keras.layers.Input(shape=(X_ROWS, len(CHARS_X)))\n","a0 = tf.keras.layers.Input(shape=(N_A,))\n","c0 = tf.keras.layers.Input(shape=(N_A,))\n","\n","a = a0\n","c = c0\n","\n","for t in range(X_ROWS):\n","  x = tf.keras.layers.Lambda(lambda x: x[:, t, :])(X)\n","  x = reshapor_x(x) # tensor needs to be of shape (batch, time step, state)\n","  a, _, c = LSTM_cell_encoder(x, initial_state=[a, c])\n","\n","# decoder\n","y_init = tf.keras.layers.Input(shape=(1, len(CHARS_Y)))\n","Y = tf.keras.layers.Input(shape=(Y_ROWS, len(CHARS_Y)))\n","\n","outputs = []\n","\n","for t in range(Y_ROWS):\n","  if t == 0:\n","    y = tf.keras.layers.Lambda(lambda y: y[:, 0, :])(y_init) # after this reshape?\n","  else:\n","    y = tf.keras.layers.Lambda(lambda y: y[:, t - 1, :])(Y)\n","  y = reshapor_y(y)\n","    \n","  a, _, c = LSTM_cell_decoder(y, initial_state=[a, c])\n","  \n","  out = densor(a)  \n","  outputs.append(out)\n","    \n","model = tf.keras.Model(inputs=[X, a0, c0, y_init, Y], outputs=outputs)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OiR6oBKqoPsv","colab_type":"code","colab":{}},"cell_type":"code","source":["opt = tf.keras.optimizers.Adam()\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","m = X_train_encoded.shape[0]\n","a0 = np.zeros((m, N_A))\n","c0 = np.zeros((m, N_A))\n","y_init = np.zeros((m, 1, len(CHARS_Y)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tUDHtvJu2Ir-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1511},"outputId":"cdfbee35-435a-4a88-f91b-c94c1409ab6b","executionInfo":{"status":"ok","timestamp":1547587849324,"user_tz":-120,"elapsed":1407,"user":{"displayName":"Ionut Calofir","photoUrl":"https://lh4.googleusercontent.com/-FegDwQfAEhI/AAAAAAAAAAI/AAAAAAAAB4U/HLBTQ0VCm98/s64/photo.jpg","userId":"09436986145457248242"}}},"cell_type":"code","source":["print('The model architecture:')\n","model.summary()"],"execution_count":55,"outputs":[{"output_type":"stream","text":["The model architecture:\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_136 (InputLayer)          (None, 7, 12)        0                                            \n","__________________________________________________________________________________________________\n","lambda_303 (Lambda)             (None, 12)           0           input_136[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_302 (Lambda)             (None, 12)           0           input_136[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_301 (Lambda)             (None, 12)           0           input_136[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_300 (Lambda)             (None, 12)           0           input_136[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_299 (Lambda)             (None, 12)           0           input_136[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_298 (Lambda)             (None, 12)           0           input_136[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_297 (Lambda)             (None, 12)           0           input_136[0][0]                  \n","__________________________________________________________________________________________________\n","reshape_34 (Reshape)            (None, 1, 12)        0           lambda_297[0][0]                 \n","                                                                 lambda_298[0][0]                 \n","                                                                 lambda_299[0][0]                 \n","                                                                 lambda_300[0][0]                 \n","                                                                 lambda_301[0][0]                 \n","                                                                 lambda_302[0][0]                 \n","                                                                 lambda_303[0][0]                 \n","__________________________________________________________________________________________________\n","input_137 (InputLayer)          (None, 128)          0                                            \n","__________________________________________________________________________________________________\n","input_138 (InputLayer)          (None, 128)          0                                            \n","__________________________________________________________________________________________________\n","lstm_34 (LSTM)                  [(None, 128), (None, 72192       reshape_34[0][0]                 \n","                                                                 input_137[0][0]                  \n","                                                                 input_138[0][0]                  \n","                                                                 reshape_34[1][0]                 \n","                                                                 lstm_34[0][0]                    \n","                                                                 lstm_34[0][2]                    \n","                                                                 reshape_34[2][0]                 \n","                                                                 lstm_34[1][0]                    \n","                                                                 lstm_34[1][2]                    \n","                                                                 reshape_34[3][0]                 \n","                                                                 lstm_34[2][0]                    \n","                                                                 lstm_34[2][2]                    \n","                                                                 reshape_34[4][0]                 \n","                                                                 lstm_34[3][0]                    \n","                                                                 lstm_34[3][2]                    \n","                                                                 reshape_34[5][0]                 \n","                                                                 lstm_34[4][0]                    \n","                                                                 lstm_34[4][2]                    \n","                                                                 reshape_34[6][0]                 \n","                                                                 lstm_34[5][0]                    \n","                                                                 lstm_34[5][2]                    \n","__________________________________________________________________________________________________\n","input_139 (InputLayer)          (None, 1, 11)        0                                            \n","__________________________________________________________________________________________________\n","lambda_304 (Lambda)             (None, 11)           0           input_139[0][0]                  \n","__________________________________________________________________________________________________\n","input_140 (InputLayer)          (None, 3, 11)        0                                            \n","__________________________________________________________________________________________________\n","reshape_35 (Reshape)            (None, 1, 11)        0           lambda_304[0][0]                 \n","                                                                 lambda_305[0][0]                 \n","                                                                 lambda_306[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_305 (Lambda)             (None, 11)           0           input_140[0][0]                  \n","__________________________________________________________________________________________________\n","lstm_35 (LSTM)                  [(None, 128), (None, 71680       reshape_35[0][0]                 \n","                                                                 lstm_34[6][0]                    \n","                                                                 lstm_34[6][2]                    \n","                                                                 reshape_35[1][0]                 \n","                                                                 lstm_35[0][0]                    \n","                                                                 lstm_35[0][2]                    \n","                                                                 reshape_35[2][0]                 \n","                                                                 lstm_35[1][0]                    \n","                                                                 lstm_35[1][2]                    \n","__________________________________________________________________________________________________\n","lambda_306 (Lambda)             (None, 11)           0           input_140[0][0]                  \n","__________________________________________________________________________________________________\n","dense_17 (Dense)                (None, 11)           1419        lstm_35[0][0]                    \n","                                                                 lstm_35[1][0]                    \n","                                                                 lstm_35[2][0]                    \n","==================================================================================================\n","Total params: 145,291\n","Trainable params: 145,291\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"Wlewk-ywrs11","colab_type":"code","outputId":"d7733ae6-5bd2-4d1e-99db-5c3a56638092","executionInfo":{"status":"ok","timestamp":1547589052826,"user_tz":-120,"elapsed":1194924,"user":{"displayName":"Ionut Calofir","photoUrl":"https://lh4.googleusercontent.com/-FegDwQfAEhI/AAAAAAAAAAI/AAAAAAAAB4U/HLBTQ0VCm98/s64/photo.jpg","userId":"09436986145457248242"}},"colab":{"base_uri":"https://localhost:8080/","height":729}},"cell_type":"code","source":["model.fit([X_train_encoded, a0, c0, y_init, y_train_encoded], list(y_train_encoded_time_step), epochs=20)"],"execution_count":56,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","45810/45810 [==============================] - 93s 2ms/step - loss: 5.0423 - dense_17_loss: 2.3150 - dense_17_acc: 0.7419 - dense_17_acc_1: 0.1804 - dense_17_acc_2: 0.1019\n","Epoch 2/20\n","45810/45810 [==============================] - 58s 1ms/step - loss: 3.6696 - dense_17_loss: 2.2758 - dense_17_acc: 0.9454 - dense_17_acc_1: 0.4991 - dense_17_acc_2: 0.1263\n","Epoch 3/20\n","45810/45810 [==============================] - 57s 1ms/step - loss: 2.9335 - dense_17_loss: 2.1502 - dense_17_acc: 0.9723 - dense_17_acc_1: 0.7335 - dense_17_acc_2: 0.1706\n","Epoch 4/20\n","45810/45810 [==============================] - 57s 1ms/step - loss: 2.5026 - dense_17_loss: 1.9447 - dense_17_acc: 0.9788 - dense_17_acc_1: 0.8137 - dense_17_acc_2: 0.2361\n","Epoch 5/20\n","45810/45810 [==============================] - 57s 1ms/step - loss: 2.1689 - dense_17_loss: 1.7206 - dense_17_acc: 0.9826 - dense_17_acc_1: 0.8486 - dense_17_acc_2: 0.3133\n","Epoch 6/20\n","45810/45810 [==============================] - 57s 1ms/step - loss: 1.7929 - dense_17_loss: 1.4125 - dense_17_acc: 0.9835 - dense_17_acc_1: 0.8764 - dense_17_acc_2: 0.4455\n","Epoch 7/20\n","45810/45810 [==============================] - 59s 1ms/step - loss: 1.3242 - dense_17_loss: 1.0069 - dense_17_acc: 0.9849 - dense_17_acc_1: 0.9024 - dense_17_acc_2: 0.6196\n","Epoch 8/20\n","45810/45810 [==============================] - 58s 1ms/step - loss: 0.8401 - dense_17_loss: 0.5766 - dense_17_acc: 0.9866 - dense_17_acc_1: 0.9219 - dense_17_acc_2: 0.8183\n","Epoch 9/20\n","45810/45810 [==============================] - 58s 1ms/step - loss: 0.4762 - dense_17_loss: 0.2792 - dense_17_acc: 0.9881 - dense_17_acc_1: 0.9494 - dense_17_acc_2: 0.9366\n","Epoch 10/20\n","45810/45810 [==============================] - 58s 1ms/step - loss: 0.2982 - dense_17_loss: 0.1458 - dense_17_acc: 0.9893 - dense_17_acc_1: 0.9644 - dense_17_acc_2: 0.9699\n","Epoch 11/20\n","45810/45810 [==============================] - 58s 1ms/step - loss: 0.2104 - dense_17_loss: 0.0944 - dense_17_acc: 0.9922 - dense_17_acc_1: 0.9737 - dense_17_acc_2: 0.9781\n","Epoch 12/20\n","45810/45810 [==============================] - 58s 1ms/step - loss: 0.1416 - dense_17_loss: 0.0532 - dense_17_acc: 0.9930 - dense_17_acc_1: 0.9820 - dense_17_acc_2: 0.9886\n","Epoch 13/20\n","45810/45810 [==============================] - 58s 1ms/step - loss: 0.1203 - dense_17_loss: 0.0449 - dense_17_acc: 0.9941 - dense_17_acc_1: 0.9847 - dense_17_acc_2: 0.9894\n","Epoch 14/20\n","45810/45810 [==============================] - 57s 1ms/step - loss: 0.1242 - dense_17_loss: 0.0503 - dense_17_acc: 0.9951 - dense_17_acc_1: 0.9835 - dense_17_acc_2: 0.9853\n","Epoch 15/20\n","45810/45810 [==============================] - 57s 1ms/step - loss: 0.0862 - dense_17_loss: 0.0302 - dense_17_acc: 0.9953 - dense_17_acc_1: 0.9889 - dense_17_acc_2: 0.9920\n","Epoch 16/20\n","45810/45810 [==============================] - 57s 1ms/step - loss: 0.0671 - dense_17_loss: 0.0261 - dense_17_acc: 0.9965 - dense_17_acc_1: 0.9931 - dense_17_acc_2: 0.9929\n","Epoch 17/20\n","45810/45810 [==============================] - 57s 1ms/step - loss: 0.0729 - dense_17_loss: 0.0302 - dense_17_acc: 0.9967 - dense_17_acc_1: 0.9924 - dense_17_acc_2: 0.9906\n","Epoch 18/20\n","45810/45810 [==============================] - 57s 1ms/step - loss: 0.0682 - dense_17_loss: 0.0293 - dense_17_acc: 0.9971 - dense_17_acc_1: 0.9916 - dense_17_acc_2: 0.9912\n","Epoch 19/20\n","45810/45810 [==============================] - 57s 1ms/step - loss: 0.0609 - dense_17_loss: 0.0287 - dense_17_acc: 0.9978 - dense_17_acc_1: 0.9940 - dense_17_acc_2: 0.9909\n","Epoch 20/20\n","45810/45810 [==============================] - 57s 1ms/step - loss: 0.0612 - dense_17_loss: 0.0256 - dense_17_acc: 0.9974 - dense_17_acc_1: 0.9930 - dense_17_acc_2: 0.9917\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f3e08f78ef0>"]},"metadata":{"tags":[]},"execution_count":56}]},{"metadata":{"id":"c7WK4YqoLaPs","colab_type":"text"},"cell_type":"markdown","source":["Predicting"]},{"metadata":{"id":"hqAUtAZAWhbe","colab_type":"code","colab":{}},"cell_type":"code","source":["#encoder\n","X_ = tf.keras.layers.Input(shape=(X_ROWS, len(CHARS_X)))\n","a0_ = tf.keras.layers.Input(shape=(N_A,))\n","c0_ = tf.keras.layers.Input(shape=(N_A,))\n","\n","a_ = a0_\n","c_ = c0_\n","\n","for t in range(X_ROWS):\n","  x_ = tf.keras.layers.Lambda(lambda x: x[:, t, :])(X_)\n","  x_ = reshapor_x(x_) # tensor needs to be of shape (batch, time step, state)\n","  a_, _, c_ = LSTM_cell_encoder(x_, initial_state=[a_, c_])\n","\n","# decoder \n","xx_ = tf.keras.layers.Input(shape=(1, len(CHARS_Y)))\n","inp = xx_\n","\n","outputs_ = []\n","\n","for t in range(Y_ROWS):\n","  y_ = tf.keras.layers.Lambda(lambda y: y[:, 0, :])(inp)\n","  \n","  y_ = reshapor_y(y_)\n","    \n","  a_, _, c_ = LSTM_cell_decoder(y_, initial_state=[a_, c_])\n","  \n","  out_ = densor(a_)\n","#   outputs_.append(out_)  \n","  \n","  inp = reshapor_y(out_)\n","  outputs_.append(inp)\n","  \n","model_inf_ = tf.keras.Model(inputs=[X_, a0_, c0_, xx_], outputs=outputs_)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"08jwwa_1Lsa2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"090ceee2-bbaf-48a0-e764-9017d2e370b8","executionInfo":{"status":"ok","timestamp":1547589141454,"user_tz":-120,"elapsed":73343,"user":{"displayName":"Ionut Calofir","photoUrl":"https://lh4.googleusercontent.com/-FegDwQfAEhI/AAAAAAAAAAI/AAAAAAAAB4U/HLBTQ0VCm98/s64/photo.jpg","userId":"09436986145457248242"}}},"cell_type":"code","source":["m_pos = 1\n","a0 = np.zeros((m_pos, N_A))\n","c0 = np.zeros((m_pos, N_A))\n","xx = np.zeros((m_pos, 1, len(CHARS_Y)))\n","\n","y_pred = []\n","for pos in range(X_test_encoded.shape[0]):\n","  p = model_inf_.predict([X_test_encoded[pos:pos+m_pos, :, :], a0, c0, xx])\n","  y_pred.append(decode_y_str(p))\n","    \n","acc = accuracy_score(y_test, y_pred)\n","print('The accuracy on the test set: {0}'.format(acc))"],"execution_count":58,"outputs":[{"output_type":"stream","text":["The accuracy on the test set: 0.9742414320017463\n"],"name":"stdout"}]},{"metadata":{"id":"KremjflddA6v","colab_type":"code","outputId":"633c457f-d5bf-48a8-e9d4-eb1a4a8e2a08","executionInfo":{"status":"ok","timestamp":1547589147848,"user_tz":-120,"elapsed":1054,"user":{"displayName":"Ionut Calofir","photoUrl":"https://lh4.googleusercontent.com/-FegDwQfAEhI/AAAAAAAAAAI/AAAAAAAAB4U/HLBTQ0VCm98/s64/photo.jpg","userId":"09436986145457248242"}},"colab":{"base_uri":"https://localhost:8080/","height":538}},"cell_type":"code","source":["nrs = np.random.randint(0, len(y_test), size=10)\n","for nr in nrs:\n","  print('Input: {0}\\n \\\n","  True sum: {1}\\n \\\n","  Predicted sum: {2}'.format(X_test[nr], y_test[nr], y_pred[nr]))"],"execution_count":59,"outputs":[{"output_type":"stream","text":["Input: 73+152\n","   True sum: 225\n","   Predicted sum: 225\n","Input: 211+135\n","   True sum: 346\n","   Predicted sum: 346\n","Input: 247+238\n","   True sum: 485\n","   Predicted sum: 485\n","Input: 48+19\n","   True sum: 67\n","   Predicted sum: 67\n","Input: 181+185\n","   True sum: 366\n","   Predicted sum: 366\n","Input: 69+223\n","   True sum: 292\n","   Predicted sum: 292\n","Input: 3+136\n","   True sum: 139\n","   Predicted sum: 139\n","Input: 194+116\n","   True sum: 310\n","   Predicted sum: 310\n","Input: 61+8\n","   True sum: 69\n","   Predicted sum: 69\n","Input: 18+158\n","   True sum: 176\n","   Predicted sum: 176\n"],"name":"stdout"}]}]}